# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_TITLE=Quiz Generation Service
API_VERSION=1.0.0
ENVIRONMENT=development

# CORS Configuration
# For development: use * to allow all origins
# For production: specify comma-separated allowed origins
ALLOWED_ORIGINS=*

# LlamaParse API
LLAMA_PARSE_API_KEY=your_llama_parse_api_key_here

# LLM API Keys
GOOGLE_API_KEY=your_google_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_MODEL=gemini-2.0-flash

# OpenRouter API (recommended for Gemini 2.0 Flash)
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=google/gemini-2.0-flash-001

# Neo4j Configuration
# Use service name 'neo4j' when running in Docker, 'localhost' when running locally
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123

# Redis Configuration
# Use service name 'redis' when running in Docker, 'localhost' when running locally
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Embedding Configuration
EMBEDDING_MODEL=all-mpnet-base-v2
EMBEDDING_DIMENSION=768
FAISS_INDEX_PATH=/app/faiss_index

# File Upload Configuration
MAX_FILE_SIZE_MB=50
ALLOWED_FILE_EXTENSIONS=.pdf,.doc,.docx,.ppt,.pptx,.txt,.png,.jpg,.jpeg

# Chunking Configuration
CHUNK_TOKEN_CAP=180
MIN_CHUNK_TOKENS=12
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200

# Candidate Selection Configuration
CANDIDATE_M_SLIDES=150
CANDIDATE_M_CHAPTERS=300
CLUSTERING_K_FACTOR=5
DEDUP_THRESHOLD=0.88

# Quiz Generation Configuration
DEFAULT_NUM_QUESTIONS=10
MAX_NUM_QUESTIONS=30
DEFAULT_DIFFICULTY=medium
DEFAULT_LANGUAGE=vi
LLM_CONCURRENCY=8
LLM_TEMPERATURE=0.2
LLM_MAX_RETRIES=3
CONFIDENCE_AUTO_ACCEPT=0.8

# Mock mode for testing (true/false)
MOCK_LLM=false
MOCK_LLAMAPARSE=false

# Logging
LOG_LEVEL=INFO
